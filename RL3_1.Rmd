---
title: "Basic Statistics"
author: "Yao-Jen Kuo"
date: "February, 2016"
output: slidy_presentation
---

## Agenda

* Sampling
* Probability Distribution
* Descriptive Statistics
* Correlations
* T-tests
* Chi-squared Test
* ANOVA

## Sampling

* The `sample()` function

```{r}
data <- c(1:10)
sample(data, 5, replace=FALSE)
sample(data, 10, replace=TRUE)
```

## Probability Distribution

* The `rnorm()` function - Generates random numbers from normal distribution

```{r}
# Generates 1,000 numbers from a normal with mean=0 and sd=1
dataRnorm <- rnorm(1000, 0, 1)
head(dataRnorm)
```

* The `dnorm()` function - Probability Density Function(PDF)

```{r}
# Gives the density (height of the PDF) of the normal with mean=0 and sd=1
dataDnorm <- dnorm(0, mean=0, sd=1)
dataDnorm
```

* The `pnorm()` function - Cumulative Distribution Function(CDF)

```{r}
# Gives the area under the standard normal curve to the left of 1.96
dataPnorm <- pnorm(1.96, mean=0, sd=1)
```

* The `qnorm()` function - Quantile Function â€“ inverse of pnorm

```{r}
# Gives the value at which the CDF of the standard normal
dataQnorm <- qnorm(0.975, 0, 1)
```

## Descriptitve Statistics

* Built-in Descriptive Statistics Functions

```{r}
data <- c(1:10)
range(data)
length(data)
mean(data)
median(data)
quantile(data, 0.5)
sd(data)
var(data)
max(data)
min(data)
summary(data)
```

* Customized `mode()` function

```{r}
mode <- function(x) {
  temp <- table(x)
  max(temp)
}
data <- c(1,2,2,3,3,3)
mode(data)
```

## Correlations

* The `cor()` function

```{r}
str(mtcars)
cor(mtcars[1:5])
```

## Binomial Tests

```{r}
binom.test(x=92, n=315, p=1/6)
```

## T-tests

* one sample t-test

Whether 2 means are significantly different.

```{r}

```

* two sample t-test

Whether the means of 2 independent groups are different.

```{r}
t.test(mtcars$mpg~mtcars$am)
```

## Chi-squared Test

Whether the distribution of categorical variables of two groups differ.

```{r}
frequencyTable <- table(mtcars$am, mtcars$cyl)
frequencyTable
chisq.test(frequencyTable)
```

## ANOVA

Analysis of variance investigates the relationship between categorical variables and numerical variables.

* One-way ANOVA

If there is only **ONE** categorical variable, perform a one-way ANOVA then.

```{r}
boxplot(mtcars$mpg~factor(mtcars$gear), xlab='gear', ylab='mpg')
onewayAnova <- aov(mtcars$mpg~factor(mtcars$gear))
summary(onewayAnova)
```

* Two-way ANOVA

If there are more than two categorical variables, perform a two-way ANOVA then.

```{r}
par(mfrow=c(1,2))
boxplot(mtcars$mpg~factor(mtcars$gear), subset=(mtcars$am==1), xlab='gear', ylab='mpg', main='Manual')
boxplot(mtcars$mpg~factor(mtcars$gear), subset=(mtcars$am==0), xlab='gear', ylab='mpg', main='Automatic')
twowayAnova <- aov(mtcars$mpg~factor(mtcars$gear)*factor(mtcars$am))
summary(twowayAnova)
```

## Reference

* R in Action, Robert I. Kabacoff
* Learning Predictive Analytics with R, Eric Mayor
* Machine Learning with R Cookbook, David Chiu
* Machine Learning with R, Brett Lantz