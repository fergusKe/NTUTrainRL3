---
title: "Introduction to Machine Learning"
author: "Yao-Jen Kuo"
date: "June, 2016"
output:
  slidy_presentation:
    fig_width: 8
    fig_height: 5
---

## 機器學習是什麼?

* 你怎麼認得一顆樹?

![Tree](images/tree.jpg)

## 機器學習的種類

* Supervised
	* 分類
	* 迴歸分析
* Unsupervised
	* 分群

## 這門課會涵蓋的內容

* 基本統計方法
* 衡量機器學習模型的表現
* 分類
* 迴歸分析
* 分群

## 分類

* 目標:預測新資料的類別
* 利用歷史資料建立出classifier
* 利用classifier預測新資料所屬類別
* 應用:
	* 醫療診斷
	* 影像辨識

## 分類(範例)

```{r, results = 'hide', message = FALSE}
packages <- c("rpart", "rattle", "rpart.plot", "RColorBrewer", "magrittr")
sapply(X = packages, FUN = library, character.only = TRUE)
```

```{r}
# 讀取資料
titanic <- read.csv(file = "C:/NTUTrainRL3/data/train.csv", header = TRUE)
titanic <- titanic[, -c(4, 9, 11)] %>% na.omit(object = .)
str(titanic)

# 隨機排列資料集
set.seed(1)
n <- nrow(x = titanic)
shuffledTitanic <- titanic[sample(n), ]

# Split the data in train and test
trainIndices <- 1:round(0.7 * n)
train <- shuffledTitanic[trainIndices, ]
testIndices <- (round(0.7 * n) + 1):n
test <- shuffledTitanic[testIndices, ]

# Build a decision tree model
tree <- rpart(formula = Survived ~ ., data = train, method = "class")
prediction <- predict(object = tree, newdata = test, type="class")
fancyRpartPlot(model = tree)
confusionMatrix <- table(x = test$Survived, y = prediction, dnn=c("Actual", "Prediction"))
confusionMatrix
```

## 迴歸分析

* 目標:預測新資料的數值
* 利用歷史資料建立出迴歸模型
* 利用迴歸模型預測新資料的數值
* 應用:
	* 信用評分

## 迴歸分析(範例)

```{r}
# 氣溫與冰紅茶銷量
temperature <- c(29, 28, 34, 31, 25, 29, 32, 31, 24, 33, 25, 31, 26, 30)
icedTeaSales <- c(77, 62, 93, 84, 59, 64, 80, 75, 58, 91, 51, 73, 65, 84)
toBePredicted <- data.frame(temperature = 30)
# 建立模型
icedTeaData <- data.frame(temperature = temperature, icedTeaSales = icedTeaSales)
lmIcedTea <- lm(formula = icedTeaSales ~ temperature, data = icedTeaData)
predicted <- predict(object = lmIcedTea, newdata = toBePredicted)
# 作圖
plot(icedTeaSales ~ temperature, xlab = "當日最高氣溫(度)", ylab = "冰紅茶銷量(杯)")
points(x = toBePredicted$temperature, y = predicted, col="green", cex = 2, pch = 18)
abline(reg = lmIcedTea$coefficients, col = "red", lwd = 2)
```

## 分群

* 目標:將資料分成群組
* 掌握組內差異小、組間差異大的原則
* 應用:
	* 客戶分群

## 分群(範例)

```{r}
# 看看鳶尾花資料集的結構
str(object = iris)
# Set random seed
irisCluster <- iris[-5]
species <- iris$Species
kmeansIris<-kmeans(x = irisCluster, centers = 3)
confusionMatrix <- table(x = species, y = kmeansIris$cluster, dnn = c("Actual", "Clustered"))
confusionMatrix
# 作圖
plot(formula = Petal.Length ~ Petal.Width, data = irisCluster, col = kmeansIris$cluster, xlab = "花瓣寬度", ylab = "花瓣長度")
```

## 推薦延伸閱讀

* [Andrew Ng, Machine Learning](https://www.coursera.org/learn/machine-learning)
* [林軒田，機器學習基石](https://www.youtube.com/user/hsuantien/playlists)