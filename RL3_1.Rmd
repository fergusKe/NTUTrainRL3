---
title: "淺談R語言與機器學習"
author: "Yao-Jen Kuo"
date: "June, 2016"
output:
  slidy_presentation:
    fig_width: 8
    fig_height: 5
---

## 自我介紹

* Senior Data Analyst at Coupang(We are hiring!)
* Analytical Consultant at SAS
* Assistant Manager at CTBC
* http://yaojenkuo.github.io/
* tonykuoyj@gmail.com

## 如何設定R語言開發環境

* [R Getting Started](https://github.com/yaojenkuo/RGettingStarted)

## 這門課的目標

* 知道什麼問題可以用機器學習作為解決的方法
* 使用R語言中**基本的**機器學習技巧
* 能夠用主管聽得懂的話解釋這些基本的技巧

## 這門課會涵蓋的內容

* 衡量機器學習模型的表現
* 分類(Classification): 決策樹, k-NN
* 迴歸分析(Regression)
* 分群(Clustering): k-means, 階層式

## 機器學習的特性

* 從過往資料的特徵來對未知資料做判讀
* 資料愈多應該要可以讓模型的表現愈好
* 你怎麼認得一顆樹?

![Tree](images/tree.jpg)

## 你的大腦可能是這樣子的過程

|紅色比例|綠色比例|藍色比例|答案|
|--------|--------|--------|----|
|0.1|0.9|0.0|樹|
|0.8|0.2|0.0|花|
|0.0|0.1|0.9|海|
|0.1|0.9|0.0|?|

* 這樣的資料型態叫做Data Frame
* 我們花一點時間了解R語言的基本資料格式(請上過R語言玩資料的同學多包涵, 或者利用這個時間溫習)

## R語言的基本資料格式

* Vector向量
* Factor因素向量
* Matrix矩陣
* Data Frame資料框
* List清單

```{r}
# Vectors
vector1 <- 1:5
vector2 <- c("a", "a", "b", "b", "c")
vector3 <- c(TRUE, TRUE, FALSE, FALSE, TRUE)
vector4 <- c(1:3, "a", TRUE)

# Factors
factor1 <- factor(vector2)
factor2 <- factor(c("fast", "moderate", "slow", "moderate", "slow"))
factor3 <- ordered(factor2, levels = c("slow", "moderate", "fast"))

# Matrix
matrix <- matrix(1:12, nrow = 3)

# Data Frame
df <- data.frame(vector1, vector2, vector3)

# List
list <- list(vector1, factor1, matrix, df)
```

## 從基本資料格式中選取元素

* 在R語言中我們使用中括號`[]`搭配`(列, 欄)`來選取元素

```{r}
vector1[1]
factor1[c(1, 2)]
matrix[1, 2]
df[, 1]
df$vector1#data frame可以使用 `$`
list[[1]][1]
```

## 探索資料框的基本函數

* 善用`?`或`help()`來幫助你瞭解函數

```{r}
nrow(cars)
ncol(cars)
dim(cars)
class(cars)
str(cars)
head(cars)
tail(cars, n = 10)
summary(cars)
```

## 什麼是機器學習?

* 什麼是樹
* 購物籃推薦(Target)
* 電影推薦(Netflix)
* 無人車
* 判別垃圾郵件
* 在臉書照片上標註你自己與朋友
* 預測2016年7月台幣兌日幣的匯率

## 什麼不是機器學習?

* 資料中出現最多的顏色是什麼?
* 2016年波士頓馬拉松男子組冠軍的成績?
* 哪一門課是系統訓練班人數最多的?
* 計算2015年台灣的薪資中位數

## 機器學習的基本種類

* 監督式學習
	* 分類(Classification)
	* 迴歸分析(Regression)
* 非監督式學習
	* 分群(Clustering)

## 分類

* 目標:預測新資料的類別
* 利用歷史資料建立出分類器
* 利用分類器預測新資料所屬類別

## 分類(決策樹範例)

* 到[Kaggle](https://www.kaggle.com/c/titanic/data)將資料集 `train.csv` 下載到本機

```{r, results = 'hide', message = FALSE, warning= FALSE}
# 載入需要使用的套件
packages <- c("rpart", "rattle", "rpart.plot", "RColorBrewer", "magrittr")
sapply(packages, FUN = library, character.only = TRUE)
```

```{r}
# 讀取資料
titanic <- read.csv("/Users/tkuo/ntu_train/NTUTrainRL3/data/train.csv", header = TRUE)
titanic <- titanic[, -c(4, 9, 11)] %>% na.omit
str(titanic)

# 隨機排列資料集
n <- nrow(titanic)
set.seed(123)
shuffledTitanic <- titanic[sample(n), ]

# 將資料集分為訓練與測試
trainIndices <- 1:round(0.7 * n)
train <- shuffledTitanic[trainIndices, ]
testIndices <- (round(0.7 * n) + 1):n
test <- shuffledTitanic[testIndices, ]

# 建立一個決策樹模型
tree <- rpart(formula = Survived ~ ., data = train, method = "class")
prediction <- predict(tree, newdata = test, type="class")
fancyRpartPlot(tree)
confusionMatrix <- table(x = test$Survived, y = prediction, dnn=c("Actual", "Prediction"))
confusionMatrix
```

* 這裡的 train, test 跟 Kaggle 提供的很容易混淆, 一定要搞清楚

## 迴歸分析

* 目標:預測新資料的數值
* 利用歷史資料建立出迴歸模型
* 利用迴歸模型預測新資料的數值

## 迴歸分析(單變數迴歸範例)

```{r}
# 氣溫與冰紅茶銷量
temperature <- c(29, 28, 34, 31, 25, 29, 32, 31, 24, 33, 25, 31, 26, 30)
icedTeaSales <- c(77, 62, 93, 84, 59, 64, 80, 75, 58, 91, 51, 73, 65, 84)
toBePredicted <- data.frame(temperature = 30)

# 建立一個線性迴歸模型
icedTeaData <- data.frame(temperature = temperature, icedTeaSales = icedTeaSales)
lmIcedTea <- lm(formula = icedTeaSales ~ temperature, data = icedTeaData)
predicted <- predict(lmIcedTea, newdata = toBePredicted)

# 模型摘要
summary(lmIcedTea)

# 作圖
plot(icedTeaSales ~ temperature, main = "依據氣溫預測冰紅茶銷量", xlab = "當日最高氣溫(度)", ylab = "冰紅茶銷量(杯)", family = "STHeiti")
points(x = toBePredicted$temperature, y = predicted, col="green", cex = 2, pch = 18)
abline(reg = lmIcedTea$coefficients, col = "red", lwd = 2)
```

## 分群

* 目標:將資料分成群組
* 掌握組內差異小、組間差異大的原則

## 分群(k-means 範例)

```{r}
# 看看鳶尾花資料集的結構
str(iris)

# 建立一個分群模型
irisCluster <- iris[-5]
kmeansIris<-kmeans(irisCluster, centers = 3, nstart = 10)

# 作圖
plot(formula = Petal.Length ~ Petal.Width, data = irisCluster, col = kmeansIris$cluster, main = "將鳶尾花做分群", xlab = "花瓣寬度", ylab = "花瓣長度", family = "STHeiti")
```

## Do It Yourself

* 註冊一個[Kaggle](https://www.kaggle.com/)帳號
* 將[UCI Repository](https://archive.ics.uci.edu/ml/index.html)加入**我的最愛**
* 註冊一個[Github](https://github.com/)帳號
* 把 R 跟 R Studio 在自己的電腦上安裝好

## 深入鑽研

* [Andrew Ng, Machine Learning](https://www.coursera.org/learn/machine-learning)
* [Johns Hopkins University, Practical Machine Learning](https://www.coursera.org/learn/practical-machine-learning)
* [林軒田，機器學習基石](https://www.youtube.com/user/hsuantien/playlists)
* [林軒田，機器學習技法](https://www.youtube.com/playlist?list=PLXVfgk9fNX2IQOYPmqjqWsNUFl2kpk1U2)